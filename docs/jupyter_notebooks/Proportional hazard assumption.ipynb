{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from lifelines import CoxPHFitter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Proportional Hazard Assumptions\n",
    "\n",
    "This Jupyter notebook is a small tutorial on how to test and fix proportional hazard problems. Recall that the proportional hazard assumption is that the ratio of the hazard of the $i$th individual and the baseline hazard is constant (that is, not a function of time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.datasets import load_rossi\n",
    "rossi = load_rossi()\n",
    "cph = CoxPHFitter()\n",
    "\n",
    "cph.fit(rossi, 'week', 'arrest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.print_summary(model=\"untransformed variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking assumptions with `check_assumptions`\n",
    "\n",
    "New to lifelines 0.16.0 is the `CoxPHFitter.check_assumptions` method. This method will compute statistics that check the proportional hazard assumption, produce plots to check assumptions, and more. Also included is an option to display advice to the console. Here's a breakdown of each information displayed:\n",
    "\n",
    " - Presented first are the results of a statistical test to test for any time-varying coefficients. A time-varying coefficient imply a covariate's influence _relative to the baseline_ changes over time. This implies a violation of the proportional hazard assumption. For each variable, we transform _time_ four times (these are common transformations of time to perform). If _lifelines_ rejects the null (that is, _lifelines_ rejects that the coefficient is not time-varying), we report this to the user.\n",
    " - Some advice is presented on how to correct the proportional hazard violation based on some summary statistics of the variable. \n",
    " - As a compliment to the above statistical test, for each variable that violates the PH assumption, visual plots of the the _scaled Schoenfeld residuals_ is presented against the four time transformations. A fitted lowess is also presented, along with 10 bootstrapped lowess lines (as an approximation to the confidence interval of the original lowess line). Ideally, this lowess line is constant (flat). Deviations away from the constant line are violations of the PH assumption. \n",
    " \n",
    "####  Why the _scaled Schoenfeld residuals_?\n",
    " \n",
    "This section can be skipped one first read. Let $s_{t,j}$ denote the scaled Schoenfeld residuals of variable $j$ at time $t$, $\\hat{\\beta_j}$ denote the maximum-likelihood estimate of the $j$th variable, and $\\beta_j(t)$ a time-varying coefficient in (fictional) alternative model that allows for time-varying coefficients. Therneau and Grambsch showed that. \n",
    "\n",
    "$$E[s_{t,j}] + \\hat{\\beta_j} = \\beta_j(t)$$\n",
    "\n",
    "The proportional hazard assumption implies that $\\hat{\\beta_j} = \\beta_j(t)$, hence $E[s_{t,j}] = 0$. This is what the above proportional hazard test is testing. Visually, plotting $s_{t,j}$ over time (or some transform of time), is a good way to see violations of $E[s_{t,j}] = 0$, along with the statisical test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.check_assumptions(rossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the proportional hazard test outside of `check_assumptions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.statistics import proportional_hazard_test\n",
    "\n",
    "results = proportional_hazard_test(cph, rossi, time_transform='rank')\n",
    "results.print_summary(decimals=3, model=\"untransformed variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the advice above, we can see that `wexp` has small cardinality, so we can easily fix that by specifying it in the `strata`. What does the `strata` do? For each unique value in the stratifying variable(s), a new baseline hazard is created. Hence, for each strata, a unique time-varying baseline can be created to fit the unique time-dependent effects of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.fit(rossi, 'week', 'arrest', strata=['wexp'])\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.check_assumptions(rossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `age` is still violating the proportional hazard assumption, we need to model it better.  From the residual plots above, we can see a the effect of age start to become negative over time. This will be relevant later. Below, we present two options to handle `age`. \n",
    "\n",
    "#### Option 1: bin variable and stratify on it\n",
    "\n",
    "The first option proposed is to bin the variable into equal-sized bins, and stratify like we did with `wexp`. There is a trade off here between estimation and information-loss. If we have large bins, we will lose information (since different values are now binned together), but we need to estimate less new baseline hazards. On the other hand, with tiny bins, we allow the `age` data to have the most \"wiggle room\", but must compute many baseline hazards each of which has a smaller sample size. Like most things, the optimial value is somewhere inbetween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossi_strata_age = rossi.copy()\n",
    "rossi_strata_age['age_strata'] = pd.cut(rossi_strata_age['age'], np.arange(0, 80, 3))\n",
    "\n",
    "rossi_strata_age[['age', 'age_strata']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the orignal, redundant, age column\n",
    "rossi_strata_age = rossi_strata_age.drop('age', axis=1)\n",
    "cph.fit(rossi_strata_age, 'week', 'arrest', strata=['age_strata', 'wexp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.print_summary(3, model=\"stratified age and wexp\")\n",
    "cph.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.check_assumptions(rossi_strata_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: introduce time-varying covariates\n",
    "\n",
    "Our second option to correct variables that violate the proportional hazard assumption is to model the time-varying component directly. This is done in two steps. The first is to transform your dataset into _episodic format_. This means that we split a subject from a single row into $n$ new rows, and each new row represents some time period for the subject. It's okay that the variables are static over this new time periods - we'll introduce some time-varying covariates later.\n",
    "\n",
    "See below for how to do this in _lifelines_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import to_episodic_format\n",
    "\n",
    "# the time_gaps parameter specifies how large or small you want the periods to be. \n",
    "rossi_long = to_episodic_format(rossi, duration_col='week', event_col='arrest', time_gaps=1.)\n",
    "rossi_long.head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject is given a new id (but can be specified as well if already provided in the dataframe). This id is used to track subjects over time. Notice the `arrest` col is 0 for all periods prior to their (possible) event as well. \n",
    "\n",
    "Above I mentioned there were two steps to correct `age`. The first was to convert to a episodic format. The second is to create an interaction term between `age` and `stop`. This is a time-varying variable.\n",
    "\n",
    "Instead of `CoxPHFitter`, we must use `CoxTimeVaryingFitter` instead since we are working with a episodic dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossi_long['time*age'] = rossi_long['age'] * rossi_long['stop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxTimeVaryingFitter\n",
    "ctv = CoxTimeVaryingFitter()\n",
    "\n",
    "ctv.fit(rossi_long, \n",
    "        id_col='id', \n",
    "        event_col='arrest', \n",
    "        start_col='start', \n",
    "        stop_col='stop', \n",
    "        strata=['wexp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv.print_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above scaled Schoenfeld residual plots for `age`, we can see there is a slight negative effect for higher time values. This is confirmed in the output of the `CoxTimeVaryingFitter`: we see that the coefficient for `time*age` is -0.005.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The point estimates and the standard errors are very close to each other using either option, we can feel confident that either approach is okay to proceed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
